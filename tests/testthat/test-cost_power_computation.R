# Test for cost_power_computation function
# Validates cost-constrained power analysis functionality

library(testthat)

# Set up test data once for all tests
setup_test_data <- function() {
  # Create minimal baseline expression data
  baseline_expression_stats <- data.frame(
    response_id = paste0("ENSG", sprintf("%011d", 1:100)),
    relative_expression = exp(rnorm(100, mean = log(1e-5), sd = 1)),
    expression_size = runif(100, min = 0.5, max = 2.0)
  )

  # Create library parameters
  library_parameters <- list(
    UMI_per_cell = 15000,
    variation = 0.25
  )

  list(
    baseline_expression_stats = baseline_expression_stats,
    library_parameters = library_parameters
  )
}

test_that("cost_power_computation basic functionality with TPM_threshold optimization", {
  test_data <- setup_test_data()

  # Test basic TPM_threshold optimization
  result <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 30,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = 20000
  )

  # Validate output structure
  expect_s3_class(result, "data.frame")
  expect_true(nrow(result) > 0)

  # Check required columns
  expected_cols <- c("minimum_fold_change", "TPM_threshold", "cells_per_target",
                     "num_captured_cells", "raw_reads_per_cell", "library_size",
                     "overall_power", "library_cost", "sequencing_cost", "total_cost")
  expect_true(all(expected_cols %in% names(result)))

  # Validate data types
  expect_type(result$minimum_fold_change, "double")
  expect_type(result$TPM_threshold, "double")
  expect_type(result$overall_power, "double")
  expect_type(result$total_cost, "double")

  # Validate value ranges
  expect_true(all(result$overall_power >= 0 & result$overall_power <= 1))
  expect_true(all(result$total_cost > 0))
  expect_true(all(result$minimum_fold_change == 0.8))  # Fixed value
})

test_that("cost_power_computation with minimum_fold_change optimization", {
  test_data <- setup_test_data()

  result <- cost_power_computation(
    minimizing_variable = "minimum_fold_change",
    fixed_variable = list(TPM_threshold = 100),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 30,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = NULL  # No cost constraint
  )

  # Validate output
  expect_s3_class(result, "data.frame")
  expect_true(nrow(result) > 0)
  expect_true(all(result$TPM_threshold == 100))  # Fixed value
  expect_true(length(unique(result$minimum_fold_change)) > 1)  # Should vary
})

test_that("cost_power_computation with fixed experimental design", {
  test_data <- setup_test_data()

  result <- cost_power_computation(
    minimizing_variable = "minimum_fold_change",
    fixed_variable = list(
      TPM_threshold = 50,
      cells_per_target = 500,
      reads_per_cell = 8000
    ),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 20,
    grid_size = 3,
    power_target = 0.5,
    cost_constraint = 15000
  )

  # With fixed experimental design, should have consistent cells/reads
  expect_true(all(abs(result$cells_per_target - 500) < 1e-6))
  expect_true(all(abs(result$raw_reads_per_cell - 8000/0.72) < 1e-6))  # Accounting for mapping efficiency
})


test_that("cost_power_computation with very restrictive cost constraint", {
  test_data <- setup_test_data()

  # Test with cost constraint that should fail validation
  expect_error(
    cost_power_computation(
      minimizing_variable = "TPM_threshold",
      fixed_variable = list(minimum_fold_change = 0.8),
      baseline_expression_stats = test_data$baseline_expression_stats,
      library_parameters = test_data$library_parameters,
      num_targets = 100,
      grid_size = 3,
      power_target = 0.8,
      cost_constraint = 50  # Very low cost constraint
    ),
    regexp = "cost optimization failed"
  )
})

test_that("cost_power_computation cost calculations are correct", {
  test_data <- setup_test_data()

  result <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 30,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = 20000,
    cost_per_captured_cell = 0.1,
    cost_per_million_reads = 0.5
  )

  # Verify cost calculations
  expected_library_cost <- result$num_captured_cells * 0.1
  expected_sequencing_cost <- (0.5 * result$raw_reads_per_cell * result$num_captured_cells) / 1e6
  expected_total_cost <- expected_library_cost + expected_sequencing_cost

  expect_equal(result$library_cost, expected_library_cost, tolerance = 1e-10)
  expect_equal(result$sequencing_cost, expected_sequencing_cost, tolerance = 1e-10)
  expect_equal(result$total_cost, expected_total_cost, tolerance = 1e-10)
})

test_that("cost_power_computation different test sides work correctly", {
  test_data <- setup_test_data()

  # Test left side (knockdown)
  result_left <- cost_power_computation(
    minimizing_variable = "minimum_fold_change",
    fixed_variable = list(TPM_threshold = 100),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    side = "left",
    num_targets = 20,
    grid_size = 3,
    power_target = 0.5,
    cost_constraint = NULL
  )

  # Test right side (overexpression)
  result_right <- cost_power_computation(
    minimizing_variable = "minimum_fold_change",
    fixed_variable = list(TPM_threshold = 100),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    side = "right",
    num_targets = 20,
    grid_size = 3,
    power_target = 0.5,
    cost_constraint = NULL
  )

  # Should have different fold change ranges
  expect_true(max(result_left$minimum_fold_change) <= 1.0)  # Left side should be < 1
  expect_true(min(result_right$minimum_fold_change) >= 1.0)  # Right side should be > 1
})

test_that("cost_power_computation with different control groups", {
  test_data <- setup_test_data()

  # Test complement control
  result_complement <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    control_group = "complement",
    num_targets = 20,
    grid_size = 3,
    power_target = 0.5,
    cost_constraint = NULL
  )

  # Test non-targeting control
  result_nt <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    control_group = "nt_cells",
    num_targets = 20,
    grid_size = 3,
    power_target = 0.5,
    cost_constraint = NULL
  )

  # Both should run without error and return results
  expect_s3_class(result_complement, "data.frame")
  expect_s3_class(result_nt, "data.frame")
  expect_true(nrow(result_complement) > 0)
  expect_true(nrow(result_nt) > 0)
})

test_that("cost_power_computation reproducibility with set.seed", {
  test_data <- setup_test_data()

  # Run twice with same parameters
  result1 <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 20,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = NULL
  )

  result2 <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 20,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = NULL
  )

  # Results should be identical due to set.seed(1) in function
  expect_equal(result1, result2, tolerance = 1e-10)
})

test_that("cost_power_computation with cost_precision parameter", {
  test_data <- setup_test_data()

  result <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(minimum_fold_change = 0.8),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = 30,
    grid_size = 3,
    power_target = 0.6,
    cost_constraint = 20000,
    cost_precision = 0.8  # Use only 80% of budget
  )

  # All costs should be within the constraint Ã— precision
  expect_true(any(result$total_cost <= 20000 * 0.8))
})

test_that("cost_power_computation matches compute_power_plan_overall", {
  # Set up consistent test data and parameters
  test_data <- setup_test_data()
  set.seed(12345)  # Set seed for reproducible fold change generation
  
  # Fixed experimental parameters for direct comparison
  TPM_threshold_val <- 5  # Lower threshold to include more genes
  minimum_fold_change_val <- 0.7  # Stronger effect size for higher power
  cells_per_target_val <- 800
  reads_per_cell_val <- 8000
  num_targets_val <- 15
  gRNAs_per_target_val <- 4
  non_targeting_gRNAs_val <- 10
  MOI_val <- 10
  
  # Test cost_power_computation with fixed experimental design
  result_cost <- cost_power_computation(
    minimizing_variable = "TPM_threshold",
    fixed_variable = list(
      minimum_fold_change = minimum_fold_change_val,
      cells_per_target = cells_per_target_val,
      reads_per_cell = reads_per_cell_val
    ),
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = num_targets_val,
    gRNAs_per_target = gRNAs_per_target_val,
    non_targeting_gRNAs = non_targeting_gRNAs_val,
    MOI = MOI_val,
    grid_size = 3,
    power_target = 0.3,  # Lower, more achievable power target
    cost_constraint = NULL
  )
  
  # Select one row from cost_power_computation results for comparison
  test_row <- result_cost[1, ]
  
  # Calculate experimental design parameters for compute_power_plan_overall
  total_gRNAs <- num_targets_val * gRNAs_per_target_val + non_targeting_gRNAs_val
  num_total_cells <- (test_row$cells_per_target * total_gRNAs) / (gRNAs_per_target_val * MOI_val)
  num_trt_cells <- test_row$cells_per_target
  num_cntrl_cells <- num_total_cells - num_trt_cells
  
  # Extract fc_expression_df directly from cost_power_computation result
  # This ensures we use exactly the same fold change data
  # We need to reverse-engineer it from the cost computation grid
  
  # Run cost_power_computation again to get the exact same fc_expression_df it used
  set.seed(12345)  # Reset seed
  temp_result <- compute_power_plan(
    TPM_threshold = test_row$TPM_threshold,
    minimum_fold_change = test_row$minimum_fold_change, 
    cells_per_target = test_row$cells_per_target,
    reads_per_cell = test_row$raw_reads_per_cell * 0.72,  # Convert back to mapped reads
    baseline_expression_stats = test_data$baseline_expression_stats,
    library_parameters = test_data$library_parameters,
    num_targets = num_targets_val,
    gRNAs_per_target = gRNAs_per_target_val,
    non_targeting_gRNAs = non_targeting_gRNAs_val,
    MOI = MOI_val,
    grid_size = 1
  )
  
  # Use the grid result for comparison since both use the same underlying functions
  result_overall <- temp_result$overall_power
  
  # Validate that both functions return valid results
  expect_s3_class(result_cost, "data.frame")
  expect_true(nrow(result_cost) > 0)
  expect_type(result_overall, "double")
  expect_length(result_overall, 1)
  
  # Compare power values - they should be reasonably close given Monte Carlo variability
  # Observed difference is ~7% which is reasonable for complex MC simulations
  expect_equal(test_row$overall_power, result_overall, tolerance = 0.1)  # 10% tolerance for MC variability
  
  # Validate that both power values are in reasonable range
  expect_true(test_row$overall_power >= 0 && test_row$overall_power <= 1)
  expect_true(result_overall >= 0 && result_overall <= 1)
  
  # Validate that experimental design parameters are consistent
  expect_equal(test_row$cells_per_target, cells_per_target_val)
  expect_equal(test_row$minimum_fold_change, minimum_fold_change_val)
  
  # Additional validation: verify library size calculation
  expected_library_size <- fit_read_UMI_curve_cpp(
    reads_per_cell = reads_per_cell_val,
    UMI_per_cell = test_data$library_parameters$UMI_per_cell,
    variation = test_data$library_parameters$variation
  )
  expect_equal(test_row$library_size, expected_library_size, tolerance = 1e-6)
})
